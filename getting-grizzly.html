---
layout: pages
title: Getting Started
tag: Grizzly
slug: getting-grizzly
baseurl: "../"
---

<div class="bs-docs-section">
  <h1 id="getting-started">Getting Started: Grizzly Release</h1>

  <p>Our guide provides an overview for installing, configuring, deploying, and supporting OpenStack and Chef. Simply click any topic and
  get started.</p>

  <div class="row">
    <div class="col-12 col-lg-6">
      <h2><a href="#about">About Chef and OpenStack</a></h2>
      <p><a href="#about-chef">About Chef</a></p>
      <p><a href="#about-openstack">About OpenStack</a></p>
    </div>

    <div class="col-12 col-lg-6">
      <h2><a href="#requirements">Requirements</a></h2>
      <p><a href="#node-requirements">Node Requirements</a></p>
      <p><a href="#software-requirements">Software Requirements</a></p>
      <p><a href="#networking-requirements">Networking Requirements</a></p>
    </div>
  </div>

  <div class="row">
    <div class="col-12 col-lg-6">
      <h2><a href="#install">Installation</a></h2>
      <p><a href="#install-chef">Install Chef</a></p>
      <p><a href="#install-openstack">Install OpenStack</a></p>
      <p><a href="#install-bootstrap-nodes">Bootstrap Your Nodes</a></p>
      <p><a href="#install-chef-nodes">Chef Your Nodes</a></p>
    </div>

    <div class="col-12 col-lg-6">
      <h2><a href="#using">Using OpenStack</a></h2>
      <p><a href="#using-private-cloud">Using Your Private Cloud</a></p>
      <p><a href="#using-our-tools">Using Our DevOps Tools</a></p>
      <p><a href="#using-deployments">Scaling and Branching Deployments</a></p>
    </div>
  </div>

  <div class="row">
    <div class="col-12 col-lg-6">
      <h2><a href="#test">Testing OpenStack</a></h2>
      <p><a href="#test-connectivity">Test Connectivity</a></p>
      <p><a href="#test-your-install">Test Your Install</a></p>
    </div>

    <div class="col-12 col-lg-6">
      <h2><a href="#sandbox">All-in-One Sandbox</a></h2>
      <p><a href="#sandbox-creation">Create Your Own Sandbox</a></p>
      <p><a href="#sandbox-vagrant">Introduction to Vagrant</a></p>
      <p><a href="#sandbox-install-process">Installation Process</a></p>
    </div>
  </div>

  <div class="row">
    <div class="col-12 col-lg-6">
      <h2><a href="#scenario">Use Scenario</a></h2>
      <p><a href="#scenario-softcube">SoftCube</a></p>
    </div>

    <div class="col-12 col-lg-6">
      <h2><a href="#support">Find Support</a></h2>
      <p><a href="#support-resources">Technical Resources</a></p>
      <p><a href="#support-components">Definitions for Components</a></p>
      <p><a href="#support-terms">Definitions for Terms</a></p>
    </div>
  </div>
</div>

<!-- Chef-OpenStack section -->
<br>

<div class="page-divider"></div>

<h1 id="about">About Chef and OpenStack</h1>

<p>The open source configuration management and automation framework used to deploy and manage many large public and private installations
supports a wide variety of deployment scenarios. This section introduces each resource, followed by supplementing documentation.</p>

<h2 id="about-chef">About Chef</h2>

<p>Chef is a systems integration framework built to bring the benefits of configuration management to your entire infrastructure. This
framework makes it easy to deploy servers and applications to any physical, virtual, or cloud location, no matter the size of the
infrastructure.</p>

<p>Each organization is composed of one (or more) workstations, a single server, and every node configured and maintained by a Chef client.
Install Chef client on every node and it will perform all necessary configuration tasks. Then come cookbooks and recipes. The Chef client
relies on these to tell it how to configure each node in your organization. You can even manage multiple environments—-or groups of nodes
and settings—-with the same Chef server. Visit <a href="https://learnchef.opscode.com">https://learnchef.opscode.com</a> for more
information.</p>

<p><img class="img-thumbnail" id="no-height" src="{{ page.baseurl }}content/images/chef-openstack/001.jpg"></p>

<h2 id="about-openstack">About OpenStack</h2>

<p>OpenStack is a free, open-source project that provides an infrastructure as a service (IaaS) for cloud computing. Backed by a vibrant
community of both individuals and companies, its technology consists of a series of interrelated projects that manage pools of
coordination, processing, storage, and networking throughout a data center.</p>

<p>OpenStack’s ability to empower deployers and administrators, manage resources through its web interface, and provide easy-to-use
command-line tools has helped it gain a lot of traction in only a few short years.</p>

<p>Visit <a href="http://docs.openstack.org">http://docs.openstack.org</a> for more information.</p>

<!-- Requirements -->

<div class="page-divider"></div>

<h1 id="requirements">Requirements</h1>

<p>Review the requirements below in their entirety before beginning installation.</p>

<h2 id="node-requirements">Node Requirements</h2>

<p>Consistent with OpenStack&#8217;s reference architecture, we recommend a minimum of the following three nodes to operate an officially
supported architecture. These are optimal for users seeking a private cloud offering on the SoftLayer platform.</p>

<ul>
  <li>Cloud Controller Node</li>

  <li>Network Node</li>

  <li>Compute Node</li>
</ul>

<blockquote>
  <p>Note: OpenStack can scale to hundreds or thousands of nodes. Running OpenStack on systems that do not meet the minimum requirements
  may negatively affect system or overall cluster performance.</p>
</blockquote>

<div class="table-responsive">
  <table class="table table-bordered table-hover">
    <thead>
      <tr>
        <th>Hardware</th>

        <th>Cloud Controller Node</th>

        <th>Network Node</th>

        <th>Compute Node</th>
      </tr>
    </thead>

    <tbody>
      <tr>
        <td>System</td>

        <td>Dual Processor</td>

        <td>Single Processor</td>

        <td>Dual Processor</td>
      </tr>

      <tr>
        <td>RAM</td>

        <td>16 GB or greater</td>

        <td>8 GB or greater</td>

        <td>16 GB or greater</td>
      </tr>

      <tr>
        <td>Processor</td>

        <td>Quad-Core Xeon or greater</td>

        <td>Quad-Core Xeon or greater</td>

        <td>Quad-Core Xeon or greater</td>
      </tr>

      <tr>
        <td>Disk (OS Drive)</td>

        <td>Two physical disks in RAID1</td>

        <td>Two physical disks in RAID1</td>

        <td>Two physical disks in RAID1</td>
      </tr>

      <tr>
        <td>Disk (MySQL Database)</td>

        <td>Two physical disks in RAID0 or RAID1, or 4+ physical disks in RAID10</td>

        <td>N/A</td>

        <td>N/A</td>
      </tr>

      <tr>
        <td>Disk (Cinder Volumes)</td>

        <td>Two physical disks1 in RAID1, or 4+ physical disks1 in RAID10</td>

        <td>N/A</td>

        <td>N/A</td>
      </tr>

      <tr>
        <td>Disk (Instance Storage)</td>

        <td>N/A</td>

        <td>N/A</td>

        <td>Two physical disks in RAID1, or 4+ physical disks in RAID10</td>
      </tr>

      <tr>
        <td>Disk Space</td>

        <td>144 GB or greater</td>

        <td>144 GB or greater</td>

        <td>144 GB or greater</td>
      </tr>

      <tr>
        <td>Network</td>

        <td>1Gbps Private and Public</td>

        <td>1Gbps Private and Public</td>

        <td>1Gbps Private and Public</td>
      </tr>
    </tbody>
  </table>
</div>

<blockquote>
  <p>(1) 10K SAS/SCSI RPM drives, or alternatively SSDs, may provide much better performance for Cinder when allocating and destroying
  volumes.</p>
</blockquote>

<h2 id="software-requirements">Software Requirements</h2>

<p>Check the requirements below to ensure your environment is compatible.</p>

<h3>Operating System</h3>

<p>OpenStack supports <strong>Ubuntu Server Minimal 12.04 LTS</strong>.</p>

<p>The SoftLayer Chef recipes make use of the <a href="https://wiki.ubuntu.com/ServerTeam/CloudArchive">Ubuntu Cloud repository</a>, which
is where current OpenStack packages are maintained. The recipes automatically handle the configuration needed to use the Ubuntu Cloud
repository.</p>

<h3>Chef</h3>

<p><strong>Chef 11.4</strong> or greater is required.</p>

<h3>Cookbooks</h3>

<p>Have the following cookbooks handy before beginning the install process. You can download them at <a href=
"https://github.com/opscode-cookbooks/mysql">Opscode Cookbooks GitHub account</a>.</p>

<ul>
  <li>
    <a href="https://github.com/opscode-cookbooks/partial_search">partial_search</a>
  </li>

  <li>
    <a href="https://github.com/opscode-cookbooks/mysql">mysql</a>
  </li>

  <li>
    <a href="https://github.com/opscode-cookbooks/ntp">ntp</a>
  </li>

  <li>
    <a href="https://github.com/opscode-cookbooks/build-essential">build_essential</a>
  </li>

  <li>
    <a href="https://github.com/opscode-cookbooks/openssl">openssl</a>
  </li>
</ul>

<h2 id="networking-requirements">Networking Requirements</h2>

<p>Within the SoftLayer environment and the Chef cookbooks provided, the reference architecture consists of three separate networks (two
physical interfaces and one virtual interface). Refer to the following diagram to determine how various components and are connected, and
the networks they&#8217;re connected to.</p>

<p><img class="img-thumbnail" id="custom-height" src="{{ page.baseurl }}content/images/requirements/001.png"></p>

<p>For OpenStack private cloud deployments, we recommend following best practices to secure your public network, exposing only the systems
and services that you wish to make available over the Internet.</p>

<p>Included below is a table you can use to reference each description and some important notes.</p>

<div class="table-responsive">
  <table class="table table-bordered table-hover">
    <thead>
      <tr>
        <th>Network</th>

        <th>Description</th>

        <th>Addressing</th>
      </tr>
    </thead>

    <tbody>
      <tr>
        <td>Private</td>

        <td>
          <ul>
            <li>Existing SoftLayer back-end network where all your hardware exists, including VLANs attached to your account.</li>

            <li>Most SoftLayer servers connect to this network on the <strong>bond0</strong> interface, but other servers may be connected
            on <strong>eth0</strong>.</li>

            <li>This provides access to other non-OpenStack servers and services on the SoftLayer private network.</li>
          </ul>
        </td>

        <td>
          <ul>
            <li>You must order an IPv4 pool of Portable <em>Private</em> IPs to dole out across instances.</li>

            <li>See important info about IP addressing.</li>
          </ul>
        </td>
      </tr>

      <tr>
        <td>Public</td>

        <td>
          <ul>
            <li>Existing SoftLayer front-end network from which all incoming Internet traffic is received and all outbound Internet traffic
            is sent.</li>

            <li>Most SoftLayer servers connect to this network on the <strong>bond1</strong> interface, but other servers may be connected
            on <strong>eth1</strong>.</li>
          </ul>
        </td>

        <td>
          <ul>
            <li>Must order an IPv4 pool of Portable <em>Public</em> IPs to dole out across instances.</li>

            <li>See important info about IP addressing.</li>
          </ul>
        </td>
      </tr>

      <tr>
        <td>Data</td>

        <td>
          <ul>
            <li>Networks created within OpenStack Quantum are part of the data network.</li>

            <li>OpenStack instances communicate with each other over the data network, including when they issue DHCP requests during boots
            and reboots.</li>

            <li>This network is an IP-over-GRE network between Network and Compute Nodes.</li>

            <li>The virtual network appliance used is Open vSwitch combined with the <code>quantum-plugin-openvswitch-agent</code> in
            Quantum.</li>
          </ul>
        </td>

        <td>
          <ul>
            <li>Default environment attributes in our cookbooks allow you to create overlapping IPv4 subnet ranges between different
            tenants and projects.</li>

            <li>See important info about IP addressing.</li>
          </ul>
        </td>
      </tr>
    </tbody>
  </table>
</div>

<h3>IP Addressing</h3>

<p>A minimum, but not recommended, range of /30 (or four total IP addresses with <strong>one</strong> usable address) is required in order
to use a SoftLayer Portable IP block within your OpenStack private cloud, whether on the public network or the private network. Whenever
possible, we recommend using blocks larger than /30.</p>

<p>As with all networks, the first IP in a subnet is reserved for addressing the subnet, the second IP is already used by the upstream
SoftLayer router (and in many networks this is the case), and the final address in the subnet is used for broadcast traffic.</p>

<p>With these constraints in mind, a /29 portable subnet would thusly provide six total with three usable IP addresses, a /28 subnet would
provide 14 total with 11 usable IP addresses, a /27 subnet would provide 30 total with 27 usable addresses, and so forth.</p>

<p>Remember that the DHCP server used in Quantum will need an IP address on each subnet where DHCP is enabled. Keep this in mind when
planning how large of a SoftLayer Portable IP block to order.</p>

<p>OpenStack utilizes NAT (Network Address Translation) across externally connected Quantum/Neutron virtual routers. Any network that
attaches to the router has external network access through NAT. The use of floating IP&#8217;s can reduce the size of the portable block
you will have to purchase by allowing all compute instances to have outbound network access when not running inbound public services.</p>

<h3>IP Constraints on Data Networks</h3>

<p>When creating new Data Networks to connect your instances, we recommend limiting Data Network subnets to the following IP ranges:</p>

<ul>
  <li>172.16.0.0/12 (or 172.16.0.0 - 172.31.255.255)</li>
  <li>192.168.0.0/16 (or 192.168.0.0 - 192.168.255.255)</li>
</ul>

<p>Please note that any instance that is simultaneously connected to the SoftLayer Private Network <strong>and</strong> Data Network subnet
within 10.0.0.0/8 is very likely to conflict and cause unforeseen problems, since the SoftLayer Private Network uses subnets within
10.0.0.0/8 as well.</p>

<p>If you absolutely need to create and use Data Network subnets within 10.0.0.0/8, ensure each instance assigned to them do not connect to
the SoftLayer Private Network.</p>

<!-- Installation -->

<div class="page-divider"></div>

<h1 id="install">Installation</h1>

<p>The instructions below will guide you through the process of installing Chef, followed by the steps for bootstrapping and configuring
your nodes to achieve a functional private cloud installation.</p>

<blockquote>
  <p>We strongly recommend that you review <a href="#requirements">OpenStack Requirements</a> before starting. This is to
  ensure that your environment is ready for install before getting in too deep.</p>
</blockquote>

<h2 id="install-chef">Install Chef</h2>

<div class="alert alert-info">You must install Chef Server first, and the Chef Server should be accessible by what will become your OpenStack nodes on ports
443 and 80.</div>

<p>The Chef server acts as a hub for configuration data. It stores cookbooks, policies applied to each node, and metadata that describes
each registered Chef node being managed by the chef-client command. Nodes use the <code>chef-client</code> command to ask the server for
configuration details, such as recipes, templates, and file distributions. The <code>chef-client</code> command then performs much of the
configuration work on the nodes themselves without much interaction with the server. This scalable approach provides consistent
configuration management and quick deployments.</p>

<p>To install Chef Server, perform the following:</p>

<ol>
  <li>Go to <a href="http://www.opscode.com/chef/install">http://www.opscode.com/chef/install</a>.
  </li>

  <li>Click the Chef Server tab.</li>

  <li>Select the operating system, version, and architecture that match the server from which you will run Chef Server.</li>

  <li>Select the version of Chef Server to download, and then click the link that appears to download the package.</li>

  <li>Install the downloaded package using the correct method for the operating system on which Chef Server will be installed. For
  instance, on Ubuntu and Debian, using <code>sudo dpkg -i package.deb</code> will perform the installation.</li>

  <li>Configure Chef Server by running the command below. This command will set up all required components, including Erchef, RabbitMQ,
  PostgreSQL, and the cookbooks that are needed by <code>chef-solo</code> to maintain Chef Server.
    <pre>
<code>$ sudo chef-server-ctl reconfigure</code>
</pre>

    <p><img class="img-thumbnail" src="{{ page.baseurl }}content/images/installation/001.png"></p>
  </li>

  <li>Verify the hostname for the server by running the <code>hostname</code> command. The hostname for the server must be a fully
  qualified domain name (<span class="caps">FQDN</span>). We recommend as well that the proper <code>A</code> records for each of your
  nodes&#8217; <span class="caps">FQDN</span>s exist in <span class="caps">DNS</span> for easier accessibility.</li>

  <li>When you&#8217;re finished, verify the installation of Chef Server by running the following command:
    <pre>
<code>$ sudo chef-server-ctl test</code>
</pre>
  </li>
</ol>

<p>This will run the <code>chef-pedant</code> test suite against the installed Chef Server and will report that everything is installed
correctly and running smoothly.</p>

<h2 id="install-openstack">Install OpenStack</h2>

<p>The instructions below provide a general overview of steps you will perform to install an OpenStack environment with private cloud. It
demonstrates a typical OpenStack installation, and includes additional information about customizing or modifying your installation.
Generally, your installation will follow these steps, with more details outlined in the other sections below.</p>

<ol>
  <li>Configure a bootstrap script with the hardware servers and/or cloud compute instances (<span class="caps">CCI</span>s) that you wish
  to bootstrap with Chef; this can be done in a simple shell script. Ensure you substitute the proper <span class="caps">FQDN</span>, the
  remote user name that has password-less <code>sudo</code> access, the local path to that user&#8217;s private <span class=
  "caps">SSH</span> key, and name of the Chef environment in which the node resides. In this example, we represent these with
    <span class="caps">FQDN</span>, <span class="caps">USER</span>, and <span class="caps">ENVIRONMENT</span>, respectively.
    <pre>
<code>knife bootstrap FQDN -x USER --sudo -i ~/.ssh/id_rsa -E ENVIRONMENT</code>
</pre>
  </li>

  <li>Edit the role information for each server and role.
    <pre>
<code>knife node run_list add FQDN &#39;role[grizzly-controller]&#39;</code>
</pre>
  </li>

  <li>Run the bootstrap script you&#8217;ve just created to prepare each server before running <code>chef-client</code>.</li>

  <li>Modify the required attributes through Chef environment overrides.</li>

  <li>Run the `chef-client` program on each server to start installation and configuration. Be sure to run the installs in this order:

    <ul>
      <li>MySQL roles</li>

      <li>RabbitMQ roles</li>

      <li>Keystone role</li>

      <li>Controller role</li>

      <li>All remaining roles</li>
    </ul>
  </li>
</ol>

<h2 id="prepare-chef">Prepare Chef</h2>

<p>Before OpenStack can be installed to any servers, the private cloud repository needs to be downloaded locally and then uploaded to your
Chef Server. To do this, prepare a default Chef directory structure with this command:</p>
<pre>
<code>$ git clone git://github.com/opscode/chef-repo.git</code>
</pre>

<p>Change directory into <code>~/chef-repo/cookbooks</code> and then download the private cloud repository:</p>
<pre>
<code>$ cd chef-repo/cookbooks
$ git clone https://github.com/softlayer/chef-openstack</code>
</pre>

<p>The private cloud repository also depends on several Opscode cookbooks. Download them into the <code>~/chef-repo/cookbooks</code>
directory:</p>
<pre>
<code>$ git clone https://github.com/opscode-cookbooks/mysql
$ git clone https://github.com/opscode-cookbooks/partial_search
$ git clone https://github.com/opscode-cookbooks/ntp
$ git clone https://github.com/opscode-cookbooks/build-essential
$ git clone https://github.com/opscode-cookbooks/openssl</code>
</pre>

<p>The needed OpenStack roles are packaged within the private cloud repository. Copy the roles from the <code>chef-openstack/</code> directory to
the <code>~/chef-repo/roles</code> directory.</p>
<pre>
<code>$ cp -r ~/chef-repo/cookbooks/chef-openstack/roles ~/chef-repo/roles</code>
</pre>

<p>Finally, upload the cookbooks and roles to your Chef server for deployment to remote nodes:</p>
<pre>
<code>$ knife cookbook upload --all
$ knife role from file ~/chef-repo/roles/*</code>
</pre>

<p>If you get any errors during the upload, check that your <code>cookbook_path</code> and <code>role_path</code> are set correctly in the
<code>~/.chef/knife.rb</code>. You can optionally re-run the <code>knife</code> configuration client.</p>

<h2 id="install-bootstrap-nodes">Bootstrap Your Nodes</h2>

<p>Bootstrapping is a Chef term for remotely deploying the chef client to a server. It creates the node and client objects in the Chef
Server and also adds client keys to both the server and client, allowing to chef-client communicate with the Chef Server.</p>

<p>Two choices are available for bootstrapping nodes. SoftLayer has provided example scripts, which can be edited for your needs, or you
can bootstrap them on your own by following a <code>chef-client</code> install guide or installing <code>chef-client</code> on your own. It
is recommended to use the bootstrap scripts.</p>

<p>Edit the script for each hardware node you would like to include in the OpenStack installation. It is highly recommended that at least
three nodes be used—-one for a controller node, one for a network node, and one for a compute node. After the bootstrap process completes,
the script will assign an OpenStack role to the hardware nodes. A node can have more than one role. A three-node bootstrap example script
is shown below.</p>
<output><pre>#!/bin/bash

## Bootstrap three nodes with chef-client, registering them with Chef Server
knife bootstrap control1.example.com -x USER --sudo -i ~/.ssh/id_rsa -E ENVIRONMENT
knife bootstrap compute2.example.com -x USER --sudo -i ~/.ssh/id_rsa -E ENVIRONMENT
knife bootstrap network3.example.com -x USER --sudo -i ~/.ssh/id_rsa -E ENVIRONMENT

## Now, add specific roles to each node&#39;s run list that will run once chef-client is run
## Controller node:
knife node run_list add control1.example.com &#39;role[grizzly-mysql-all]&#39;
knife node run_list add control1.example.com &#39;role[grizzly-rabbitmq]&#39;
knife node run_list add control1.example.com &#39;role[grizzly-cinder]&#39;
knife node run_list add control1.example.com &#39;role[grizzly-keystone]&#39;
knife node run_list add control1.example.com &#39;role[grizzly-glance]&#39;
knife node run_list add control1.example.com &#39;role[grizzly-controller]&#39;

## Compute node:
knife node run_list add compute2.example.com &#39;role[grizzly-compute]&#39;

## Network node:
knife node run_list add network3.example.com &#39;role[grizzly-network]&#39;</pre></output>

<h2 id="configure-chef">Configure Chef</h2>

<p>You will need to override some attributes for your OpenStack Chef deployment. These can be overridden at the environment level or at the
node level, but the environment level is <strong>strongly</strong> recommended.</p>

<p>First, create an environment. It will be used to house your nodes and configuration attributes. The attribute overrides will modify the
OpenStack for your deployment without the need to edit the recipes directly.</p>
<pre>
<code>$ knife environment create NAME -d &quot;Description for environment&quot;</code>
</pre>

<p>Edit your environment with the following command (you may also edit this from the Chef web-based UI). An editor will open where you may
define your environment&#8217;s attributes in <span class="caps">JSON</span> format.</p>
<pre>
<code>$ knife environment edit ENVIRONMENT</code>
</pre>

<p>Take special care to ensure your final environment document is valid <span class="caps">JSON</span>, as <code>knife</code> may discard
your attempted change if the <span class="caps">JSON</span> does not properly validate once you save and exit the editor.</p>

<p>The following is an example of the recommended minimum attributes that can be overridden in the environment, illustrating the required
attributes to deploy:</p>
<output><pre>"override_attributes": {
    "admin": {
      "password": "admin_pass"
    },
    "network": {
      "public_interface": "eth1",
      "private_interface": "eth0"
    },
    "quantum": {
      "db": {
        "password": "my_new_quantum_pass"
      },
      "softlayer_public_portable": "XX.XX.XX.XX/YY",
      "softlayer_private_portable": "AA.AA.AA.AA/BB"
    },
    "nova": {
      "db": {
        "password": "my_new_nova_pass"
      }
    },
    "glance": {
      "db": {
        "password": "my_new_glance_pass"
      }
    },
    "keystone": {
      "db": {
        "password": "my_new_keystone_pass"
      }
    },
    "cinder": {
      "db": {
        "password": "my_new_cinder_pass"
      }
    }
  }
}</pre></output>

<h2 id="install-chef-nodes">Chef Your Nodes</h2>

<p>The process below outlines how to sequentially <em>chef</em> the nodes. The order in which services come online is important. All
OpenStack components depend on MySQL and RabbitMQ, therefore those roles must be completed before attempting to deploy OpenStack-specific
components.</p>

<h3>MySQL and RabbitMQ Nodes</h3>

<p>If you have chosen to make the MySQL node separate from the controller, you must first complete a deployment of the MySQL role
<strong>prior</strong> to chefing another node with any OpenStack services. You may easily deploy MySQL roles for each OpenStack component
by adding your additional nodes to the sample script above and specifying which MySQL role(s) to apply to each. This is discussed in the
Scaling &amp; Branching Deployments section.</p>

<p>Similarly, if you intend to deploy RabbitMQ on a separate server, you may follow the same process, but deploying the RabbitMQ role must
be performed prior to chefing the controller with any OpenStack services. It is independent of the MySQL roles.</p>

<p>Otherwise, please skip to the next step if MySQL and RabbitMQ will run from your controller node.</p>

<h3>Controller Node</h3>

<p>The controller node contains, at a minimum, the roles for the base Quantum and Nova services. If you are unfamiliar with OpenStack, it
is recommended to do a standard installation as illustrated in the bootstrap example. Be sure that Chef shows that the node contains the
MySQL backend, RabbitMQ, Keystone, Cinder, and Glance roles. You can verify this with a simple <code>knife</code> command:</p>
<pre>
<code>knife node show FQDN</code>
</pre>

<p>The output should look similar to this:</p>
<output><pre>Node Name: control1.example.com
Environment: Region
FQDN: control1.example.com
IP: XX.XX.XX.XX
Run List: role[grizzly-mysql-cinder], role[grizzly-mysql-glance], role[grizzly-mysql-keystone], role[grizzly-mysql-nova], role[grizzly-mysql-quantum], role[grizzly-rabbitmq], role[grizzly-keystone], role[grizzly-controller], role[grizzly-cinder], role[grizzly-glance]
Roles: grizzly-mysql-cinder, grizzly-mysql-glance, grizzly-mysql-keystone, grizzly-mysql-nova, grizzly-mysql-quantum, grizzly-rabbitmq, grizzly-keystone, grizzly-controller, grizzly-cinder, grizzly-glance
Recipes: chef-openstack::set_attributes, chef-openstack::set_cloudnetwork, ntp, chef-openstack::mysql-cinder, chef-openstack::mysql-glance, chef-openstack::mysql-keystone, chef-openstack::mysql-nova, chef-openstack::mysql-quantum, chef-openstack::ip_forwarding, chef-openstack::repositories, chef-openstack::rabbitmq-server, chef-openstack::keystone, chef-openstack::quantum-controller, chef-openstack::nova, chef-openstack::dashboard, chef-openstack::cinder, chef-openstack::glance, chef-openstack::quantum-network
Platform: ubuntu 12.04
Tags:
</pre></output>

<p>To chef the controller node you can either connect directly to the remote server and (with root privileges) run <code>chef-client</code>
from the node itself or use <a href="http://docs.opscode.com/knife_ssh.html">knife ssh</a> to run it from the Chef server:</p>
<pre>
<code>knife ssh SEARCH_TERM &#39;sudo chef-client&#39;</code>
</pre>

<p>For example:</p>
<pre>
<code>knife ssh &#39;role:grizzly-controller&#39; &#39;sudo chef-client&#39;</code>
</pre>

<p>&#8230;or</p>
<pre>
<code>knife ssh &#39;name:FQDN&#39; &#39;sudo chef-client&#39;</code>
</pre>

<h3>Other Network and Compute Nodes</h3>

<p>After the MySQL, RabbitMQ, and controller roles have been chefed, any of the remaining roles can then be run in any order for the other
nodes, and can even be run in parallel to speed up your total deployment time. Compute and Network nodes can also be added any time after
the initial deployment. Following the example above, the two commands would chef your network and compute nodes:</p>
<pre>
<code>## Compute node:
knife ssh &#39;name:FQDN_2&#39; &#39;sudo chef-client&#39;</code>
<code>## Network node:
knife ssh &#39;name:FQDN_3&#39; &#39;sudo chef-client&#39;</code>
</pre>

<!-- Using OpenStack -->

<div class="page-divider"></div>

<h1 id="using">Using OpenStack</h1>

<p>Here’s how to start getting familiar with the OpenStack client utilities.</p>

<h2 id="using-private-cloud">Using Your Private Cloud</h2>

<p>You can access the OpenStack command-line tools by logging in to the Controller node via <span class="caps">SSH</span> as root, and
running the following commands:</p>
<pre>
<code># source .openrc</code>
</pre>
<pre>
<code># nova flavor-list</code>
</pre>

<p>The output should look similar to this:</p>
<output><pre>
+----+-----------+-----------+------+-----------+------+-------+-------------+-----------+
| ID |    Name   | Memory_MB | Disk | Ephemeral | Swap | VCPUs | RXTX_Factor | Is_Public |
+----+-----------+-----------+------+-----------+------+-------+-------------+-----------+
| 1  | m1.tiny   | 512       | 0    | 0         |      | 1     | 1.0         | True      |
| 2  | m1.small  | 2048      | 10   | 20        |      | 1     | 1.0         | True      |
| 3  | m1.medium | 4096      | 10   | 40        |      | 2     | 1.0         | True      |
| 4  | m1.large  | 8192      | 10   | 80        |      | 4     | 1.0         | True      |
| 5  | m1.xlarge | 16384     | 10   | 160       |      | 8     | 1.0         | True      |
+----+-----------+-----------+------+-----------+------+-------+-------------+-----------+
</pre></output>

<p>This is a list of &#8220;flavors&#8221; — different disk, memory, and <span class="caps">CPU</span> allocations that you can assign to
instances. This is an example of the information that you can access through the python-novaclient command line client.</p>

<p>The list of available images to boot from is seen by this command.</p>
<pre>
<code># nova image-list</code>
</pre>

<p>The output should look similar to this:</p>
<output><pre>
+--------------------------------------+-----------------------------------+--------+--------+
| ID                                   | Name                              | Status | Server |
+--------------------------------------+-----------------------------------+--------+--------+
| 3470a8b5-46a7-442b-ac75-7c8f663e271d | CirrOS 0.3.0 i386                 | ACTIVE |        |
| ace57487-30b6-41c9-9e7a-9d44f103437d | CirrOS 0.3.0 x86_64               | ACTIVE |        |
| 3722fed6-0065-4521-b480-8abd5f7abf2c | Fedora 18 (Cloud) i386            | ACTIVE |        |
| 21c3f3ae-f773-46f9-8fef-d3c0a712ef45 | Fedora 18 (Cloud) x86_64          | ACTIVE |        |
| dbda560c-8e09-4035-9332-03ef4470a934 | Fedora 19 (Cloud) i386            | ACTIVE |        |
| c2ac12e3-5f11-4679-8074-232c5040b901 | Fedora 19 (Cloud) x86_64          | ACTIVE |        |
| 2baacb65-fa9d-4707-9856-5b6d5803d63e | Ubuntu 12.04 Server (Cloud) amd64 | ACTIVE |        |
| 49a33caa-8e78-41c3-8af6-cc5ea25182f2 | Ubuntu 12.04 Server (Cloud) i386  | ACTIVE |        |
| 5b8998ce-40fa-43cb-9f79-11f4e9a32296 | Ubuntu 12.10 Server (Cloud) amd64 | ACTIVE |        |
| e8f69a8b-c1f5-4432-89bb-6bfecfea7cc3 | Ubuntu 12.10 Server (Cloud) i386  | ACTIVE |        |
| 668e92c6-b6c0-4f9e-bf0d-078ede9667e9 | Ubuntu 13.04 Server (Cloud) amd64 | ACTIVE |        |
| 169fc708-cdbf-4dd3-a106-ced48a88922f | Ubuntu 13.04 Server (Cloud) i386  | ACTIVE |        |
+--------------------------------------+-----------------------------------+--------+--------+
</pre></output>

<p>To launch an instance, find the image ID and flavor name you would like to use.</p>
<pre>
<code># nova boot --flavor=2 --image=2baacb65-fa9d-4707-9856-5b6d5803d63e ubuntu</code>
</pre>

<p>The output should look similar to this:</p>
<output><pre>
+-------------------------------------+--------------------------------------+
| Property                            | Value                                |
+-------------------------------------+--------------------------------------+
| status                              | BUILD                                |
| updated                             | 2013-10-02T21:18:01Z                 |
| OS-EXT-STS:task_state               | None                                 |
| OS-EXT-SRV-ATTR:host                | None                                 |
| key_name                            | None                                 |
| image                               | Ubuntu 12.04 Server (Cloud) amd64    |
| hostId                              |                                      |
| OS-EXT-STS:vm_state                 | building                             |
| OS-EXT-SRV-ATTR:instance_name       | instance-00000001                    |
| OS-EXT-SRV-ATTR:hypervisor_hostname | None                                 |
| flavor                              | m1.small                             |
| id                                  | e12449f2-0dfb-4aee-b7cf-8c97850c2b30 |
| security_groups                     | [{u'name': u'default'}]              |
| user_id                             | 36fcdb3ca5d349ffb82731b91c522080     |
| name                                | ubuntu                               |
| adminPass                           | RKTRUH52zfGL                         |
| tenant_id                           | a06ad73e633b4a479986f8de4b613e51     |
| created                             | 2013-10-02T21:18:01Z                 |
| OS-DCF:diskConfig                   | MANUAL                               |
| metadata                            | {}                                   |
| accessIPv4                          |                                      |
| accessIPv6                          |                                      |
| progress                            | 0                                    |
| OS-EXT-STS:power_state              | 0                                    |
| OS-EXT-AZ:availability_zone         | nova                                 |
| config_drive                        |                                      |
+-------------------------------------+--------------------------------------+
</pre></output>

<p>You can also view the status of the controller and compute nodes and the Nova components active on each while logged in as the root
user.</p>
<pre>
<code># nova-manage service list</code>
</pre>

<p>The output should look similar to this:</p>
<output><pre>
Binary Host Zone Status State Updated_At
nova-conductor control1 nova enabled :-) 2013-09-20 10:41:39
nova-cert control1 nova enabled :-) 2013-09-20 10:41:36
nova-scheduler control1 nova enabled :-) 2013-09-20 10:41:34
nova-consoleauth control1 nova enabled :-) 2013-09-20 10:41:41
nova-compute compute2 nova enabled :-) 2013-09-20 10:41:35
</pre></output>

<p>You can also view logs with the tail command. For example, to view nova-compute.log on your compute node(s), execute the following
command:</p>
<pre>
<code># tail /var/log/nova/nova-compute.log</code>
</pre>

<p>All logs are available in the /var/log/ directory and its subdirectories. You may also view the status of Quantum agents that reside on
your network and compute nodes.</p>
<pre>
<code># quantum agent-list</code>
</pre>

<p>The output should look similar to this:</p>
<output><pre>
+--------------------------------------+--------------------+----------+-------+----------------+
| id                                   | agent_type         | host     | alive | admin_state_up |
+--------------------------------------+--------------------+----------+-------+----------------+
| 42b5f9cb-7244-499d-826a-2a056d987c44 | Open vSwitch agent | compute2 | :-)   | True           |
| c9846df5-5e13-4f7c-971e-c65dd660a2cb | Open vSwitch agent | network3 | :-)   | True           |
| 8eb94efa-8f41-44c8-8dc0-1387959de7be | DHCP agent         | network3 | :-)   | True           |
| d6fdc505-094b-4bcd-9cca-32410aa5e6e3 | L3 agent           | network3 | :-)   | True           |
+--------------------------------------+--------------------+----------+-------+----------------+
</pre></output>

<h3>Accessing the Horizon Dashboard</h3>

<blockquote>
  <p>Note: Log in with the admin user name and the password you created during the OpenStack Chef deployment.</p>
</blockquote>

<p>In addition to the command line, you can use your web browser to access the controller host. You can use the hostname or the IP address
that you provided during installation, followed by &#8220;/horizon&#8221;. For instance, if your controller is
&#8220;control1.example.com”, navigate to http://control1.example.com/horizon/. You should see the OpenStack dashboard login page. If not,
the installation may not be complete.</p>

<p>After logging in, you can configure additional users, create, and manage OS images and other volumes, create or customize flavors, and
launch instances. You also have the ability to view and create networks, routers, and subnets for use in your OpenStack environment.</p>

<h3>OpenStack Client Utilities</h3>

<p>The OpenStack client utilities are a convenient way to interact with OpenStack using the command line from your own workstation without
logging in to the controller node. The client utilities for Python are available via PyPi and can be installed on most Linux systems with
these commands:</p>
<pre>
<code>pip install python-keystoneclient
pip install python-novaclient
pip install python-quantumclient
pip install python-cinderclient
pip install python-glanceclient</code>
</pre>

<blockquote>
  <p>Note: Individual utilities are maintained by differing communities. Refer to their help documentation for more information, or by
  using the &#8212;help flag for a given utility.</p>
</blockquote>

<h2 id="using-our-tools">Our DevOps Tools</h2>

<p>We offer two new tools to help interact with the SoftLayer environment:</p>

<ol>
  <li>sl, a command line tool to view and manage SoftLayer resources (using our Python client library)</li>
  <li>swftp-chef, a Chef cookbook for swftp, our <span class="caps">SFTP</span>/SCP-based interface to Swift Object Storage</li>
</ol>
<p>

<h3>SoftLayer Command Line Tool</h3>

<p>When working with lots of servers, whether virtual or hardware, being able to automate tasks can be a blessing. While on a <span class=
"caps">CLI</span>, quickly sorting and grepping is commonplace for those in DevOps roles, but if you have found yourself writing something
like this, these tools are probably for you:</p>
<pre>
<code>$ cat /proc/cpuinfo | grep &quot;model name&quot; | awk &#39;{ print $NF }&#39;</code>
</pre>

<p>We have extended the SoftLayer Python bindings to also ship with a new command line tool: sl. Simply install from PyPI, configure them
with your user name and <span class="caps">API</span> key, and you are ready to go.</p>
<pre>
<code>## This command requires the python-setuptools package to be installed:
$ sudo easy_install softlayer

## This alternative method requires the python-pip package to be installed:
$ sudo pip install softlayer

## Then, set up your config, which will require your user name and <span class="caps">API</span> key:
$ sl config setup</code>
</pre>

<p>Voila! You are all setup and ready to rock. Give it a test run by trying out some of these commands:</p>
<pre>
<code>$ sl --help
$ sl cci list
$ sl hardware list
$ sl dns list
$ sl dns list | grep 20.. # notice how we adjusted the output for you? Great for sed/awk use.
$ sl dns list --format=table &gt; dns_zones.txt # redirects pretty tables output to a file.</code>
</pre>

<p>Development for this tool is out in the open on GitHub at <a href=
"https://github.com/softlayer/softlayer-api-python-client">https://github.com/softlayer/softlayer-api-python-client</a>. Documentation for
it is also available on GitHub at <a href=
"https://softlayer-api-python-client.readthedocs.org/en/latest">https://softlayer-api-python-client.readthedocs.org/en/latest</a>. Do note
that this is not full <span class="caps">API</span> documentation as seen on the SoftLayer Developer Network (<span class=
"caps">SLDN</span>) site, however it is a great resource for SoftLayer Python <span class="caps">API</span> references and examples.</p>

<h3>The swftp-chef Cookbook</h3>

<p>To support our DevOps comrades even further, we have released swftp-chef. This simplifies the deployment of swftp—an <span class=
"caps">SFTP</span>-based interface to Swift—in your fleet even more. Installing is as simple as running one of these two commands:</p>
<pre>
<code>## If you have the knife-github gem installed, obtain it with this command:
$ knife cookbook github install softlayer/chef-swftp

## Otherwise, obtain it with this command:
$ knife cookbook site install swftp</code>
</pre>

<p>Afterwards, set the attributes on either the role/environment and add it to your run list. You can find a full list of swftp attributes
in its README file.</p>

<h2 id="using-deployments">Scaling and Branching Deployments</h2>

<p>The private cloud recipes were designed with scaling in mind. OpenStack was built to be scaled, but most small deployments adhere to the
three-node model of a Compute, Network, and Controller node. SoftLayer provides several options for deployers who need to scale out. You
can add Compute and Network nodes where necessary to compensate for load, and you can branch components of the install to separate servers
in any configuration you choose. Going to be a heavy user of block storage? Move the Cinder role to a separate server and deploy it as the
sole component on that system.</p>

<p>The private cloud is made up of 12 components:</p>

<ul>
  <li>OpenStack MySQL Servers</li>

  <li>Quantum/Neutron</li>

  <li>Nova</li>

  <li>Cinder</li>

  <li>Glance</li>

  <li>Keystone</li>

  <li>RabbitMQ</li>

  <li>OpenStack Controller</li>

  <li>OpenStack Nova Compute</li>

  <li>OpenStack Quantum/Neutron</li>

  <li>OpenStack Keystone Authentication</li>

  <li>OpenStack Glance</li>

  <li>OpenStack Cinder</li>
</ul>
<p>

<p>The components (roles) can be branched into the traditional three-node OpenStack model.</p>

<div class="table-responsive" id="component-table">
  <table class="table table-hover" id="no-borders">
    <thead>
      <tr>
        <th>Server</th>

        <th>Role(s)</th>
      </tr>
    </thead>

    <tbody>
      <tr>
        <td>OpenStack Controller</td>

        <td>MySQL</td>
      </tr>

      <tr>
        <td></td>

        <td>RabbitMQ</td>
      </tr>

      <tr>
        <td></td>

        <td>Keystone</td>
      </tr>

      <tr>
        <td></td>

        <td>Controller</td>
      </tr>

      <tr>
        <td></td>

        <td>Glance</td>
      </tr>

      <tr>
        <td></td>

        <td>Cinder</td>
      </tr>

      <tr>
        <td>OpenStack Compute</td>

        <td>Nova</td>
      </tr>

      <tr>
        <td>OpenStack Network</td>

        <td>Quantum/Neutron</td>
      </tr>
    </tbody>
  </table>
</div>

<p>At scale, you may wish to have some separation of these roles to handle the increased load on any single component. Database roles can
actually be split and scaled out to suit environments with heavy database churn or a desire for stronger isolation, helping to more evenly
distribute load:</p>

<div class="table-responsive" id="component-table">
  <table class="table table-hover" id="no-borders">
    <thead>
      <tr>
        <th>Server</th>

        <th>Role(s)</th>
      </tr>
    </thead>

    <tbody>
      <tr>
        <td>OpenStack Controller</td>

        <td>MySQL</td>
      </tr>

      <tr>
        <td></td>

        <td>Quantum/Neutron</td>
      </tr>

      <tr>
        <td></td>

        <td>Nova</td>
      </tr>

      <tr>
        <td></td>

        <td>RabbitMQ</td>
      </tr>

      <tr>
        <td></td>

        <td>Controller</td>
      </tr>

      <tr>
        <td>OpenStack Authentication</td>

        <td>Keystone</td>
      </tr>

      <tr>
        <td></td>

        <td>MySQL</td>
      </tr>

      <tr>
        <td></td>

        <td>Keystone</td>
      </tr>

      <tr>
        <td>OpenStack Block Storage</td>

        <td>Cinder</td>
      </tr>

      <tr>
        <td></td>

        <td>MySQL</td>
      </tr>

      <tr>
        <td></td>

        <td>Cinder</td>
      </tr>

      <tr>
        <td>OpenStack Image Store</td>

        <td>Glance</td>
      </tr>

      <tr>
        <td></td>

        <td>MySQL</td>
      </tr>

      <tr>
        <td></td>

        <td>Glance</td>
      </tr>

      <tr>
        <td>OpenStack Compute</td>

        <td>Nova</td>
      </tr>

      <tr>
        <td>OpenStack Network</td>

        <td>Quantum/Neutron</td>
      </tr>
    </tbody>
  </table>
</div>

<p>In such a scenario, high load on a single component is far less likely to adversely affect the performance of another component. This
flexibility allows you to use the hardware you already have more effectively—before having to spend money on beefier hardware.</p>

<!-- Testing OpenStack -->

<div class="page-divider"></div>

<h1 id="test">Testing OpenStack</h1>

<p>Use the testing procedures below before pushing your server into a production environment. Additionally, in case you want to create your
own testing environment (or sandbox), those instructions are also included below.</p>

<h2 id="test-connectivity">Test Connectivity</h2>

<p>The hostname for each server must meet the following requirements:</p>

<ol>
  <li>The hostname must be a fully qualified domain name (FQDN), which includes the domain suffix. Example: mychefserver.example.com (not
  simply mychefserver).</li>

  <li>The hostname must be resolvable. In most cases, such as for a server that will run in a production environment, add the hostname for
  the server to the DNS system. In some cases, such as when deploying server into a testing environment, just adding the hostname to the
  /etc/hosts file is enough to ensure that a hostname is resolvable.</li>
</ol>

<h3>Resolvable Hostname</h3>

<p>To verify if a hostname is resolvable, run the following command:</p>
<pre>
<code>$ hostname -f</code>
</pre>

<p>If the hostname is resolvable, it will return something like:</p>
<pre>
<code>mychefserver.example.com</code>
</pre>

<p>Alternatively, you can <code>ping</code> the host:</p>
<pre>
<code>$ ping mychefserver.example.com

PING mychefserver.example.com (127.0.0.1) 56(84) bytes of data.
64 bytes from mychefserver.example.com (127.0.0.1): icmp_req=1 ttl=64 time=0.034 ms
64 bytes from mychefserver.example.com (127.0.0.1): icmp_req=2 ttl=64 time=0.028 ms
64 bytes from mychefserver.example.com (127.0.0.1): icmp_req=3 ttl=64 time=0.014 ms
64 bytes from mychefserver.example.com (127.0.0.1): icmp_req=4 ttl=64 time=0.014 ms</code>
</pre>

<h3>Check Connectivity</h3>

<p>A simple routine to mark off your checklist is making sure that each server is able to communicate with the rest of the cluster. This is
important when preparing for deployment and for testing afterward. To do this use the ping&nbsp;command to ping the other server's
FQDN.</p>
<pre>
<code>$ ping control1.example.com
$ ping compute2.example.com
$ ping network3.example.com</code>
</pre>

<h2 id="test-your-install">Test Your Install</h2>

<p>Run the following commands on the controller node to check if OpenStack has been deployed and is running correctly. Before running them,
be sure to update your bash environment with the correct OpenStack variables to use them:</p>
<pre>
<code># source .openrc</code>
</pre>

<h3>Nova</h3>
<output><pre>root@control1:~# nova-manage service list 

Binary           Host      Zone             Status     State Updated_At                                                                         
nova-cert        control1  internal         enabled    :-)   2013-09-03 15:21:29
nova-scheduler   control1  internal         enabled    :-)   2013-09-03 15:21:29
nova-conductor   control1  internal         enabled    :-)   2013-09-03 15:21:29
nova-consoleauth control1  internal         enabled    :-)   2013-09-03 15:21:30
nova-compute     compute2  nova             enabled    :-)   2013-09-03 15:21:23
</pre></output>

<p>Each service or agent will display a&nbsp;<code>:-)</code>&nbsp;if they are running correctly, and&nbsp;<code>XX</code>&nbsp;if they are
not.</p>

<h3>Quantum/Neutron</h3>
<output><pre>root@control1:~# quantum agent-list

+--------------------------------------+--------------------+----------+-------+----------------+                                                
| id                                   | agent_type         | host     | alive | admin_state_up |
+--------------------------------------+--------------------+----------+-------+----------------+
| 438d2dd2-daf3-496c-99ad-179ed307b8d6 | Open vSwitch agent | compute2 | :-)   | True           |
| 4c684b66-16db-4853-8cb3-51098c3752b3 | L3 agent           | network3 | :-)   | True           |
| 98c3d818-0ebe-4cd6-89bf-0f107a7532ab | DHCP agent         | network3 | :-)   | True           |
| dd3b9134-ab76-440a-ba7a-70135202eb82 | Open vSwitch agent | network3 | :-)   | True           |
+--------------------------------------+--------------------+----------+-------+----------------+
</pre></output>

<p>Each service or agent will display a <code>:-)</code> if they are running correctly, and&nbsp;<code>XX</code> if they are not.</p>

<h3>Glance</h3>


<output><pre class="nowrap">
<div style="width:828px; overflow-x: scroll; overflow-y: hidden;">root@control1:~# glance image-list

+--------------------------------------+-----------------------------------+-------------+------------------+-----------+--------+
| ID                                   | Name                              | Disk Format | Container Format | Size      | Status |
+--------------------------------------+-----------------------------------+-------------+------------------+-----------+--------+
| 3470a8b5-46a7-442b-ac75-7c8f663e271d | CirrOS 0.3.0 i386                 | qcow2       | bare             | 9159168   | active |
| ace57487-30b6-41c9-9e7a-9d44f103437d | CirrOS 0.3.0 x86_64               | qcow2       | bare             | 9761280   | active |
| 3722fed6-0065-4521-b480-8abd5f7abf2c | Fedora 18 (Cloud) i386            | qcow2       | bare             | 226492416 | active |
| 21c3f3ae-f773-46f9-8fef-d3c0a712ef45 | Fedora 18 (Cloud) x86_64          | qcow2       | bare             | 228196352 | active |
| dbda560c-8e09-4035-9332-03ef4470a934 | Fedora 19 (Cloud) i386            | qcow2       | bare             | 235536384 | active |
| c2ac12e3-5f11-4679-8074-232c5040b901 | Fedora 19 (Cloud) x86_64          | qcow2       | bare             | 237371392 | active |
| 2baacb65-fa9d-4707-9856-5b6d5803d63e | Ubuntu 12.04 Server (Cloud) amd64 | qcow2       | bare             | 251985920 | active |
| 49a33caa-8e78-41c3-8af6-cc5ea25182f2 | Ubuntu 12.04 Server (Cloud) i386  | qcow2       | bare             | 230621184 | active |
| 5b8998ce-40fa-43cb-9f79-11f4e9a32296 | Ubuntu 12.10 Server (Cloud) amd64 | qcow2       | bare             | 221642752 | active |
| e8f69a8b-c1f5-4432-89bb-6bfecfea7cc3 | Ubuntu 12.10 Server (Cloud) i386  | qcow2       | bare             | 219938816 | active |
| 668e92c6-b6c0-4f9e-bf0d-078ede9667e9 | Ubuntu 13.04 Server (Cloud) amd64 | qcow2       | bare             | 235143168 | active |
| 169fc708-cdbf-4dd3-a106-ced48a88922f | Ubuntu 13.04 Server (Cloud) i386  | qcow2       | bare             | 233308160 | active |
+--------------------------------------+-----------------------------------+-------------+------------------+-----------+--------+
</div></pre></output>

<h3>Cinder</h3>

<p>If you haven't created any Cinder volumes yet, this command will return nothing. Otherwise, a list of created volumes will be
returned.</p>

<output><pre class="nowrap">
<div style="width:828px; overflow-x: scroll; overflow-y: hidden;">root@control1:~# cinder list

+--------------------------------------+-----------+--------------+------+-------------+----------+-------------+
|                  ID                  |   Status  | Display Name | Size | Volume Type | Bootable | Attached to |
+--------------------------------------+-----------+--------------+------+-------------+----------+-------------+
| e60def40-03a0-4e08-a9e5-3f60be89ad57 | available |     test     |  1   |     None    |  false   |             |
+--------------------------------------+-----------+--------------+------+-------------+----------+-------------+
</div></pre></output>

<h3>Keystone</h3>

<p>Keystone authentication has several commands that are worth checking, especially if you are experience any difficulty with user
accounts, OpenStack component communication, or authentication problems.</p>

<p>For detailed information on troubleshooting and debugging Keystone, please refer to its documentation at <a href=
"http://docs.openstack.org/">http://docs.openstack.org</a>.</p>

<h4>Check Keystone Users</h4>
<output><pre>root@control1:~# keystone user-list

+----------------------------------+----------+---------+--------------------+
|                id                |   name   | enabled |       email        |
+----------------------------------+----------+---------+--------------------+
| 36fcdb3ca5d349ffb82731b91c522080 |  admin   |   True  |   root@localhost   |
| 01b0af86bb1e4062b04882a03bff9758 |  cinder  |   True  |  cinder@localhost  |
| 2e15846831884959a6fc0be96a9bceaf |   demo   |   True  |   demo@localhost   |
| ee1ffd860b9940c9bedcbd27e5439333 |  glance  |   True  |  glance@localhost  |
| 62a9c425721f48d8892a9132e23ede03 |   nova   |   True  |   nova@localhost   |
| b22df525c6714c259189fd2da82b72af | quantum  |   True  | quantum@localhost  |
+----------------------------------+----------+---------+--------------------+
</pre></output>

<h4>Check Keystone Tenants</h4>
<output><pre>root@control1:~# keystone tenant-list

+----------------------------------+--------------------+---------+
|                id                |        name        | enabled |
+----------------------------------+--------------------+---------+
| a06ad73e633b4a479986f8de4b613e51 |       admin        |   True  |
| bb4f6b6e17314255b49a39fbe9fdff58 |        demo        |   True  |
| be05a0ac2e034f3aa43ac06a90943a14 | invisible_to_admin |   True  |
| cc0804251a5145c485ad87ab384350be |      service       |   True  |
+----------------------------------+--------------------+---------+
</pre></output>

<h4>Check Keystone Services</h4>
<output><pre>root@control1:~# keystone service-list

+----------------------------------+----------+----------+------------------------------+
|                id                |   name   |   type   |         description          |
+----------------------------------+----------+----------+------------------------------+
| fd9b4f0ed7434504a8938d6e8b674455 |  cinder  |  volume  |   OpenStack Volume Service   |
| 05a89640b8d04a5c902b86d4bfbb9a8f |   ec2    |   ec2    |    OpenStack EC2 service     |
| 844e120b3b594f68838e6b0e5a227427 |  glance  |  image   |   OpenStack Image Service    |
| 1ef9095e84d44658a66a46aabe4ef551 | keystone | identity |      OpenStack Identity      |
| 8f50ec8454b9432b94cd7d68172dc98a |   nova   | compute  |  OpenStack Compute Service   |
| 3de9a5a7e57943739f59c014554ea602 | quantum  | network  | OpenStack Networking service |
+----------------------------------+----------+----------+------------------------------+
</pre></output>

<p>Keystone endpoints are extremely important and can cripple your deployment when not configured correctly. However, Chef wires up the
necessary endpoint information correctly during deployment. In any event, checking the endpoint list to make sure it's correct is always a
good idea when troubleshooting issues connecting or authenticating to Keystone. Each endpoint should correspond to the correct server in
your cluster. Note that the ports in the example below are the defaults, and may vary if you've overridden the default attributes for
them.</p>

<output><pre class="nowrap">
<div style="width:828px; overflow-x: scroll; overflow-y: hidden;">root@openstack1:~# keystone endpoint-list

+----------------------------------+---------+-------------------------------------------+-------------------------------------------+-------------------------------------------+----------------------------------+
|                id                |  region |                 publicurl                 |                internalurl                |                  adminurl                 |            service_id            |
+----------------------------------+---------+-------------------------------------------+-------------------------------------------+-------------------------------------------+----------------------------------+
| 0a9d0209521e40c4820c224e3e1a015d | Region  |       http://XX.XX.XX.XX:5000/v2.0        |       http://XX.XX.XX.XX:5000/v2.0        |       http://XX.XX.XX.XX:35357/v2.0       | 1ef9095e84d44658a66a46aabe4ef551 |
| 33766366fb4e4e919d441116f46a6900 | Region  | http://XX.XX.XX.XX:8776/v1/$(tenant_id)s  | http://XX.XX.XX.XX:8776/v1/$(tenant_id)s  | http://XX.XX.XX.XX:8776/v1/$(tenant_id)s  | fd9b4f0ed7434504a8938d6e8b674455 |
| 4d6f3fb4758442068e73b808a0501864 | Region  |  http://XX.XX.XX.XX:8773/services/Cloud   |  http://XX.XX.XX.XX:8773/services/Cloud   |  http://XX.XX.XX.XX:8773/services/Admin   | 05a89640b8d04a5c902b86d4bfbb9a8f |
| 87343c685ef5477b81075017159e1a39 | Region  |         http://XX.XX.XX.XX:9696/          |         http://XX.XX.XX.XX:9696/          |         http://XX.XX.XX.XX:9696/          | 3de9a5a7e57943739f59c014554ea602 |
| e81953d02428499bb981e78be560bc88 | Region  |        http://XX.XX.XX.XX:9292/v2         |        http://XX.XX.XX.XX:9292/v2         |        http://XX.XX.XX.XX:9292/v2         | 844e120b3b594f68838e6b0e5a227427 |
| f560ac6915f241019b95e103146326dd | Region  | http://XX.XX.XX.XX:8774/v2/$(tenant_id)s  | http://XX.XX.XX.XX:8774/v2/$(tenant_id)s  | http://XX.XX.XX.XX:8774/v2/$(tenant_id)s  | 8f50ec8454b9432b94cd7d68172dc98a |
+----------------------------------+---------+-------------------------------------------+-------------------------------------------+-------------------------------------------+----------------------------------+
</div></pre></output>

<!-- All-in-One Sandbox -->

<div class="page-divider"></div>

<h1 id="sandbox">All-in-One Sandbox</h1>

<p>This section is designed to illustrate a proof-of-concept installation for learning or development purposes, in which you may wish to
run everything on a single machine. This installation process includes:</p>

<h2 id="sandbox-creation">Create Your Own Sandbox</h2>

<ol>
  <li>Installing VirtualBox on your laptop or desktop</li>

  <li>Installing Vagrant on your laptop or desktop</li>

  <li>Creating one VirtualBox VM for Chef Server</li>

  <li>Creating a second VirtualBox VM for OpenStack</li>

  <li>Deploying OpenStack in your second VM using the Chef Server in your first VM</li>
</ol>

<h2 id="sandbox-vagrant">Introduction to Vagrant</h2>

<p>Vagrant provides a quick and configuration-free platform to test drive the SoftLayer private cloud recipes on your own. Vagrant uses
VirtualBox to preconfigure virtual machines without manual intervention. In this section, Vagrant will be used to deploy Chef Server,
install the SoftLayer private cloud cookbook, and then provision the OpenStack all-in-one node. This workflow is similar to what is seen in
a production environment, and will work for Microsoft Windows and most Linux distributions.</p>

<h2 id="sandbox-install-process">Installation Process</h2>

<p>Follow the instructions below to install Virtual Box and Vagrant.</p>

<h3 id="install-virtualbox">Install VirtualBox</h3>

<ol>
  <li>Go to the <a href="https://www.virtualbox.org/wiki/Downloads">Virtual Box download page</a>.

    <p><img class="img-thumbnail" height="550px" src="{{ page.baseurl }}content/images/sandbox/006.png"></p>
  </li>

  <li>Download the AMD64 version for your operating system.</li>

  <li>Install VirtualBox using the downloaded package. For example, on Ubuntu and Debian Linux, run the following command:
    <pre>
<code>$ dpkg -i virtualbox-4.2_4.2.18-88780~Ubuntu~precise_amd64.deb</code>
</pre>
  </li>

  <li>On Windows, proceed through installation using the setup wizard:

    <p><img class="img-thumbnail" src="{{ page.baseurl }}content/images/sandbox/004.png"></p>
  </li>
</ol>

<h3 id="install-vagrant">Install Vagrant</h3>

<ol>
  <li>Go to the <a href="http://downloads.vagrantup.com">Vagrant download page</a>.
  </li>

  <li>Click the latest version. (At the time this guide was written, the most recent version was 1.3.3.)

    <p><img class="img-thumbnail" src="{{ page.baseurl }}content/images/sandbox/003.png"></p>
  </li>

  <li>Download the package for your operating system.</li>

  <li>Install Vagrant from the package.

    <p><img class="img-thumbnail" src="{{ page.baseurl }}content/images/sandbox/004.png"></p>
  </li>
</ol>

<h4>Download the Vagrant File Scripts</h4>

<ol>
  <li>Make a temporary directory to place the Vagrant files.

    <ul>
      <li>Linux command:
        <pre>
<code>$ mkdir ~/softlayer</code>
</pre>
      </li>

      <li>Windows command:
        <pre>
<code>&gt; mkdir C:\softlayer</code>
</pre>
      </li>
    </ul>
  </li>

  <li>Next, save the Vagrant files to the created location and open a terminal window or Windows command line window.</li>

  <li>Change your directory (cd) to the vagrant directory you just created.</li>

  <li>Run vagrant up.</li>

  <li>The install will take approximately 15 minutes, and will provision two VirtualBox VMs, install Chef Server, and bootstrap the
  OpenStack installation.</li>

  <li>After completion, the Vagrant script will tell you how to access the new Chef Server, as well as Horizon (the OpenStack dashboard).

    <p><img class="img-thumbnail" src="{{ page.baseurl }}content/images/sandbox/007.png"></p>
  </li>
</ol>

<h3 id="navigation">Navigation</h3>

<blockquote>
  <p>Note: Vagrant uses VirtualBox to deploy Chef Server and OpenStack. Running OpenStack compute instances inside an already virtualized
  environment is very slow compared to the speed of a hardware deployment.</p>
</blockquote>

<h3>Chef Server</h3>

<ol>
  <li>From your computer’s browser, navigate to <a href="https://127.0.0.1/">https://127.0.0.1/</a>.
  </li>

  <li>The Chef server uses a self-generated, unsigned certificate. There will be a prompt to accept and proceed.</li>

  <li>The Chef Server login prompt will be next. Enter in the following credentials:

    <ul>
      <li>username: admin</li>

      <li>password: p@ssw0rd1</li>
    </ul>

    <p><img class="img-thumbnail" src="{{ page.baseurl }}content/images/sandbox/009.png"></p>
  </li>
</ol>

<h3>OpenStack</h3>

<ol>
  <li>From your computer’s browser, navigate to <a href="http://127.0.0.1:7081/horizon/">http://127.0.0.1:7081/horizon/</a>.
  </li>

  <li>Log into OpenStack using the provided credentials:

    <ul>
      <li>username: admin</li>

      <li>password: passwordsf</li>
    </ul>

    <p><img class="img-thumbnail" src="{{ page.baseurl }}content/images/sandbox/010.png"></p>
  </li>
</ol><!-- Use Scenario -->

<div class="page-divider"></div>

<h1 id="scenario">OpenStack Use Scenario</h1>

<p>OpenStack is a cloud-computing project. It allows the implementer to create a private datacenter and provides everything needed for a
private cloud experience:</p>

<ul>
  <li>Virtual Machines/Instances</li>

  <li>Block Storage</li>

  <li>Networking</li>
</ul>

<p>While it&#8217;s very time-consuming to set up manually on your own, our Chef recipes make it simple to get up and running quickly. As
an example, let&#8217;s look at fictional company called SoftCube.</p>

<h2 id="scenario-softcube">SoftCube</h2>

<p>SoftCube is a new startup. They expect a large boom in new customers and need the ability to adjust quickly to a changing set of
requirements. Using a private cloud will provide them with the flexibility and adaptability that they need. To make this happen, SoftCube
needs to move three of their existing hardware servers to the cloud. Currently, they have two web servers and one database server.</p>

<p><img class="img-thumbnail" src="{{ page.baseurl }}content/images/use-scenario/017.png"></p>

<p>These servers reside on-site and neither of them have redundant power or networking. Let&#8217;s get them moved to the SoftLayer Private
Cloud that SoftCube just decided to purchase.</p>

<p>SoftCube will need OpenStack compute instances to replace their hardware servers. SoftCube is a security-conscious company, they will
use key-based <span class="caps">SSH</span> authentication to access their compute instances—the default behavior for new compute instances
in OpenStack. But, before creating these instances, we&#8217;ll need to create the <span class="caps">SSH</span> key that will be used to
access them. Then, each time SoftCube creates a new instance, OpenStack can inject the <span class="caps">SSH</span> key, and they&#8217;ll
use the key each time they need to log in to one of their servers.</p>

<h2 id="create-key">Create an <span class="caps">SSH</span> Key</h2>

<p>To create an <span class="caps">SSH</span> key, you&#8217;ll follow these simple steps in the Horizon dashboard.</p>

<ol>
  <li>Log in to the Horizon dashboard running on SoftCube&#8217;s new SoftLayer Private Cloud.

    <p><img class="img-thumbnail" src="{{ page.baseurl }}content/images/use-scenario/006.png"></p>
  </li>

  <li>Click on the &#8220;Project&#8221; tab.

    <p><img class="img-thumbnail" src="{{ page.baseurl }}content/images/use-scenario/016.png"></p>
  </li>

  <li>Select your Current Project (admin in this case).</li>

  <li>Click &#8220;Access &amp; Security&#8221;.

    <p><img class="img-thumbnail" src="{{ page.baseurl }}content/images/use-scenario/001.png"></p>
  </li>

  <li>Click the &#8220;Keypairs&#8221; tab.</li>

  <li>Click &#8220;Create Keypair&#8221;.</li>

  <li>Name the new keypair &#8220;SoftCube-Admin&#8221; and click the blue &#8220;Create Keypair&#8221; button.</li>

  <li>Now that the keypair is created, download it by clicking the provided link if it does not start automatically.</li>
</ol>

<h3 id="create-instances">Create Compute Instances</h3>

<p>Now that SoftCube&#8217;s keypair is available, the compute instances can be created.</p>

<ol>
  <li>Click on the &#8220;Project&#8221; tab.</li>

  <li>Select your Current Project (admin in this case).</li>

  <li>Click &#8220;Instances&#8221;.

    <p><img class="img-thumbnail" src="{{ page.baseurl }}content/images/use-scenario/010.png"></p>
  </li>

  <li>Click the &#8220;Launch Instances&#8221; button.</li>

  <li>A new dialog window will appear with all the details needed for launching a new compute instance. In the launch instance window, they
  will need the following information handy to create and launch their instances: (1) Image type, (2) Name, (3) Flavor, (4) Keypair, and
  (5) Network information. Additional volume and post-creation options may be needed in SoftCube&#8217;s future, but are not necessary to
  specify right now.</li>

  <li>On the &#8220;Details&#8221; tab, provide these options.

    <ul>
      <li>Instance Source: Image</li>

      <li>Image: Ubuntu 12.04 Server (Cloud) amd64</li>

      <li>Instance Name: web1.softcube.com</li>

      <li>Flavor: m1.medium</li>
    </ul>

    <p><img class="img-thumbnail" src="{{ page.baseurl }}content/images/use-scenario/004.png"></p>
  </li>

  <li>Click on the &#8220;Access &amp; Security&#8221; tab.

    <ul>
      <li>&#8220;SoftCube-Admin&#8221; should be already selected as the <span class="caps">SSH</span> key, but if not, select it from the
      list.</li>

      <li>Uncheck the &#8220;default&#8221; security group.</li>

      <li>Check the &#8220;basic-ssh-icmp&#8221; security group.</li>
    </ul>

    <p><img class="img-thumbnail" src="{{ page.baseurl }}content/images/use-scenario/012.png"></p>
  </li>
</ol>

<h3>Configure Network Access</h3>

<p>SoftCube&#8217;s web servers will need both internet access and private network access with each other. They&#8217;ve decided to use
floating IPs in OpenStack to handle inbound public access to their web servers, private network access for all three servers, and no public
network access to their database server. This network setup requires each web server to have two network connections, as illustrated
below.</p>

<ol>
  <li>Click on the &#8220;Networking&#8221; tab.

    <p><img class="img-thumbnail" src="{{ page.baseurl }}content/images/use-scenario/005.png"></p>
  </li>

  <li>In the &#8220;Available Networks&#8221; list, click the &#8220;+&#8221; button next to &#8220;stack-network&#8221; and
  &#8220;softlayer-private&#8221;.</li>

  <li>Click the &#8220;Launch&#8221; button. The first web server will be launched. Since SoftCube needs two web servers, follow the same
  steps to create a second web server with the name web2.softcube.com.</li>

  <li>Lastly, they&#8217;ll need an instance for the database server. Since SoftCube wants to plan for growth as early as possible, they
  will tweak a few changes to the instance configuration.</li>

  <li>On the &#8220;Details&#8221; tab, provide these options:

    <ul>
      <li>Instance name: db.softcube.com</li>

      <li>Flavor: m1.large (for a beefier amount of compute power)</li>
    </ul>
  </li>

  <li>On the &#8220;Access &amp; Security&#8221; tab, provide the same options as your web server.

    <ul>
      <li>On the &#8220;Networking&#8221; tab under &#8220;Available Networks&#8221;, click the &#8220;+&#8221; button next to
      &#8220;softlayer-private&#8221;.</li>

      <li>Click the &#8220;Launch&#8221; button. Within seconds, the database instance will launch, and SoftCube will be on the private
      cloud!</li>
    </ul>
  </li>
</ol>

<h3>Allocate Public IP Addresses</h3>

<p>We&#8217;re getting closer, but we aren&#8217;t quite finished yet. Each web server will need a public IP for inbound public access.
Currently, the compute instances are only accessible via the devices connected to OpenStack Quantum/Neutron network, or any device that is
on the SoftLayer Private Network. SoftCube can allocate public IP addresses purchased from SoftLayer to any instance at any time by
assigning Floating IPs, which is our next step.</p>

<ol>
  <li>From the Instances list, click the &#8220;More&#8221; dropdown for web1.softcube.com.</li>

  <li>Click &#8220;Associate Floating IP&#8221;.

    <p><img class="img-thumbnail" src="{{ page.baseurl }}content/images/use-scenario/003.png"></p>
  </li>

  <li>Currently SoftCube has no allocated Floating IPs. One will need to be allocated before it will before it can be assigned to a compute
  instance. Click the &#8220;+&#8221; button to associate a floating IP with the current project.

    <p><img class="img-thumbnail" src="{{ page.baseurl }}content/images/use-scenario/013.png"></p>
  </li>

  <li>We need floating IPs provided to us from the &#8220;softlayer-public&#8221; network, so ensure it is selected as the Pool, and click
  the &#8220;Allocate IP&#8221; button.</li>

  <li>The Manage Floating IP Associations dialog box will appear with a public IP address pre-populated. Ensure the web1.softcube.com
  server is selected as well, and click &#8220;Associate&#8221;.

    <p><img class="img-thumbnail" src="{{ page.baseurl }}content/images/use-scenario/014.png"></p>
  </li>

  <li>Horizon will attach the new public IP address to the web1.softcube.com instance, and display it in the &#8220;IP Address&#8221;
  column in the instances list. Sometimes this may take a moment to update, but by this time the IP address has already been routed to the
  instance.

    <p><img class="img-thumbnail" src="{{ page.baseurl }}content/images/use-scenario/015.png"></p>
  </li>

  <li>Follow the same steps above to allocate another floating IP address to web2.softcube.com.</li>
</ol>

<h3>Final Touches</h3>

<p>SoftCube now has three OpenStack compute instances:</p>

<ul>
  <li>Two web servers with public inbound access</li>

  <li>One database server that is accessible only on the backend</li>
</ul>

<p>At this point, they can start transitioning their aging, hardware-based web and database servers to their new OpenStack instances.</p>

<p>Looks like SoftCube is well on its way to a successful future in the private cloud.</p>

<!-- Find Support -->

<div class="page-divider"></div>

<h1 id="support">Finding Support for OpenStack</h1>

<p>If this is new for you, becoming familiar with the components and terminology could help dial back the frustration that comes with being
thrown into the fire.</p>

<h2 id="support-resources">Technical Resources</h2>

<p>Check out these OpenStack-related articles at our <a href="http://sldn.softlayer.com">SoftLayer Development Network (SLDN)</a>:</p>

<ul>
  <li>
    <a href="http://sldn.softlayer.com/blog/klandreth/New-DevOps-tools-SoftLayer">New DevOps tools for SoftLayer</a>
  </li>

  <li>
    <a href="http://sldn.softlayer.com/article/Introduction-Object-Storage">An Introduction to Object Storage</a>
  </li>

  <li>
    <a href="http://sldn.softlayer.com/blog/kmcdonald/FTPSFTP-SoftLayer-Object-Storage">FTP/SFTP for SoftLayer Object Storage</a>
  </li>
</ul>

<h2 id="support-components">Definitions for Components</h2>

<p>Instead of using the names of the components, specialists in the OpenStack community always use the code/project names. This table
translates those for you.</p>

<div class="table-responsive">
  <table class="table table-bordered table-hover">
    <thead>
      <tr>
        <th>Components</th>

        <th>Name</th>

        <th>Description</th>
      </tr>
    </thead>

    <tbody>
      <tr>
        <td>Identity / Authentication</td>

        <td>Keystone</td>

        <td>Provides authentication, token validation, and service URLs for each service to authorized users.</td>
      </tr>

      <tr>
        <td>Compute</td>

        <td>Nova</td>

        <td>Manages all hypervisor interaction, management, and instance state.</td>
      </tr>

      <tr>
        <td>Networking</td>

        <td>Quantum (Neutron)</td>

        <td>Manages state for all networks defined within a cluster, and provides network routing, IP management, DHCP, and load
        balancing.</td>
      </tr>

      <tr>
        <td>Image Management</td>

        <td>Glance</td>

        <td>Maintains state and stores copies of OS images for use in new instance deployments.</td>
      </tr>

      <tr>
        <td>Block Storage</td>

        <td>Cinder</td>

        <td>Allocates and manages block storage for instances, whether secondary, tertiary, etc. disks that are attached to instances. Also
        stores and manages snapshots created from instances.</td>
      </tr>

      <tr>
        <td>Object Storage</td>

        <td>Swift</td>

        <td>Provides generic object storage services, usually as a more generic file store.</td>
      </tr>

      <tr>
        <td>Management UI</td>

        <td>Horizon</td>

        <td>Allows administrators and end-users to manage each of the above.</td>
      </tr>
    </tbody>
  </table>
</div>

<h2 id="support-terms">Definitions for Terms</h2>

<p>The list below contains only basic terms found throughout our documentation. For a beefier, more comprehensive list, go to <a href=
"http://docs.openstack.org/glossary/content/glossary.html">http://docs.openstack.org/glossary/content/glossary</a>.</p>

<div class="table-responsive">
  <table class="table table-bordered table-hover">
    <thead>
      <tr>
        <th>Term</th>

        <th>Definition</th>
      </tr>
    </thead>

    <tbody>
      <tr>
        <td>Action</td>

        <td>Providers take idempotent actions to configure resources.</td>
      </tr>

      <tr>
        <td>Attribute</td>

        <td>Attributes are data about nodes.</td>
      </tr>

      <tr>
        <td>Authentication</td>

        <td>Clients authenticate to a server using pre-shared RSA keys and signed HTTP headers.</td>
      </tr>

      <tr>
        <td>Auto-vivify</td>

        <td>Internally in the library, attributes are automatically created as methods.</td>
      </tr>

      <tr>
        <td>Bootstrap</td>

        <td>In this context, bootstrap means to get Chef installed and ready to run on the target system.</td>
      </tr>

      <tr>
        <td>
          <a href="http://wiki.opscode.com/display/chef/Chef+Client">Client</a>
        </td>

        <td>The client communicates with a server to download the cookbooks it needs to compile and run its configuration.</td>
      </tr>

      <tr>
        <td>Configuration Management</td>

        <td>Setting up all the various components and services on a server so it can fulfill a role is configuration management.</td>
      </tr>

      <tr>
        <td>Convergence</td>

        <td>The process by which systems are brought in line with the overall configuration management policy.</td>
      </tr>

      <tr>
        <td>
          <a href="http://wiki.opscode.com/display/chef/Cookbooks">Cookbook</a>
        </td>

        <td>Chef cookbooks are packages for code used to configure some aspect of a system.</td>
      </tr>

      <tr>
        <td>DSL</td>

        <td>Programming or specification language dedicated to a specific problem domain. Chef makes use of meta-programming features in
        Ruby to create a simple DSL for writing recipe, role, and metadata files.</td>
      </tr>

      <tr>
        <td>
          <a href="http://wiki.opscode.com/display/chef/Data+Bags">Data Bag</a>
        </td>

        <td>Arbitrary store of JSON data that is indexed for Search.</td>
      </tr>

      <tr>
        <td>Definition</td>

        <td>Allow creation of new resource macros that string together other resources.</td>
      </tr>

      <tr>
        <td>Environments</td>

        <td>Provide a mechanism for managing different segmented spaces such as production, staging, development, and testing, with one
        Chef setup (or one organization on Hosted Chef): allowing you to set policies to dictate which versions of a given cookbook may be
        used within an infrastructure segment.</td>
      </tr>

      <tr>
        <td>File</td>

        <td>Specificity File specificity is a special order, which Chef looks for host-, platform-version- or platform-specific files to
        use when downloading/configuring file and template resources.</td>
      </tr>

      <tr>
        <td>
          <a href="http://github.com">Git</a>
        </td>

        <td>Git is a distributed version control system.</td>
      </tr>

      <tr>
        <td>Idempotent</td>

        <td>A mathematical term that means multiple applications of the same action should not change the result.</td>
      </tr>

      <tr>
        <td>Index</td>

        <td>Most data (all but Cookbooks) stored on the Chef Server are indexed for Search.</td>
      </tr>

      <tr>
        <td>Infrastructure</td>

        <td>Applications run on Infrastructure. Infrastructure in this context is not physical or virtualized things like servers or
        networking. Rather, infrastructure is the application itself, plus all the underlying software prerequisites, server settings,
        tweaks, and configuration files need for it to function properly. Infrastructure typically spans nodes, and often networks.</td>
      </tr>

      <tr>
        <td>JSON</td>

        <td>JavaScript Object Notation is a lightweight data format that is easy to read and write. All the APIs used in Chef are driven by
        JSON data.</td>
      </tr>

      <tr>
        <td>
          <a href="http://wiki.opscode.com/display/chef/Knife">Knife</a>
        </td>

        <td>A command-line tool used to work with a Chef Server and local Chef Repository.</td>
      </tr>

      <tr>
        <td>
          <a href="http://wiki.opscode.com/display/chef/Libraries">Library</a>
        </td>

        <td>In a Chef cookbook, a Library is arbitrary Ruby code that can be used to extend Chef’s language, or rollout new features.</td>
      </tr>

      <tr>
        <td>
          <a href="http://www.merbivore.com">Merb</a>
        </td>

        <td>Merb is a lightweight MVC framework used by the Chef Server to provide the API that clients communicate with.</td>
      </tr>

      <tr>
        <td>Metadata</td>

        <td>Chef cookbooks use metadata to provide hints to the Chef Server about what cookbooks should be deployed to a node, and can be
        used in user interfaces built on top of Chef.</td>
      </tr>

      <tr>
        <td>
          <a href="http://wiki.opscode.com/display/chef/Nodes">Node</a>
        </td>

        <td>A node is a system that is configured in an environment.</td>
      </tr>

      <tr>
        <td>Operating System</td>

        <td>An operating system manages hardware and provides services for running application software.</td>
      </tr>

      <tr>
        <td>Organization</td>

        <td>In Hosted Chef, an organization represents a company, department or other grouped set of servers infrastructure managed by
        Chef.</td>
      </tr>

      <tr>
        <td>Platform</td>

        <td>Chef detects the Operating System it is running on through Ohai, and uses that platform primarily to determine what provider to
        use for particular resources.</td>
      </tr>

      <tr>
        <td>Provider</td>

        <td>A provider is an abstraction on top of system commands or API calls that is used to configure a resource. Providers are often
        Operating System specific, such as the provider that installs packages for Debian (APT), Red Hat (Yum) or ArchLinux (Pacman).</td>
      </tr>

      <tr>
        <td>Provision</td>

        <td>The act of installing an operating system on bare metal, virtual machine or cloud computing instances is provisioning. Before
        Chef can configure and integrate systems, the system must first be provisioned, and then bootstrapped. This process varies by
        Operating System platform.</td>
      </tr>

      <tr>
        <td>Queue</td>

        <td>The Chef SOLR search index uses a queue for incoming data that needs to be indexed for search on the Chef Server.</td>
      </tr>

      <tr>
        <td>
          <a href="http://wiki.opscode.com/display/chef/Recipes">Recipe</a>
        </td>

        <td>A recipe is a Ruby DSL configuration file that you write to encapsulate resources that should be configured by Chef.</td>
      </tr>

      <tr>
        <td>
          <a href="http://wiki.opscode.com/display/chef/Chef+Repository">Repository</a>
        </td>

        <td>A Chef Repository is a directory where you store all the various code used to configure your infrastructure with Chef.</td>
      </tr>

      <tr>
        <td>
          <a href="http://wiki.opscode.com/display/chef/Resources">Resource</a>
        </td>

        <td>A resource is an abstraction that represents a particular thing that needs to be configured, such as a package or a
        service.</td>
      </tr>

      <tr>
        <td>
          <a href="http://en.wikipedia.org/wiki/Representational_State_Transfer">REST</a>
        </td>

        <td>“REpresentational State Transfer (REST) is a style of software architecture for distributed hypermedia systems”, commonly
        associated with HTTP. APIs conforming to REST constraints are “RESTful”. Chef uses a RESTful API.</td>
      </tr>

      <tr>
        <td>
          <a href="http://wiki.opscode.com/display/chef/Roles">Role</a>
        </td>

        <td>A role describes a set of functionality for nodes through recipes and attributes.</td>
      </tr>

      <tr>
        <td>
          <a href="http://ruby-lang.org/">Ruby</a>
        </td>

        <td>Ruby is an object-oriented programming language. Chef is written in Ruby and uses a number of Ruby DSLs for writing recipe,
        role, and metadata as code.</td>
      </tr>

      <tr>
        <td>Run</td>

        <td>List A run list is an array of recipes and roles that should be applied in order on the Node, or in another Role.</td>
      </tr>

      <tr>
        <td>
          <a href="http://lucene.apache.org/solr">SOLR</a>
        </td>

        <td>SOLR is a full text search engine platform written in Java.</td>
      </tr>

      <tr>
        <td>
          <a href="http://wiki.opscode.com/display/chef/Search">Search</a>
        </td>

        <td>Data stored by the Chef Server is indexed for Search and can be queried with SOLR’s Lucene search syntax.</td>
      </tr>

      <tr>
        <td>
          <a href="http://wiki.opscode.com/display/chef/Shef">Shef</a>
        </td>

        <td>The Chef read-eval-print loop (REPL), Shef, is a way to run Chef in an IRB session. IRB is an interactive Ruby console.</td>
      </tr>

      <tr>
        <td>
          <a href="http://wiki.opscode.com/display/chef/Chef+Solo">Solo</a>
        </td>

        <td>Chef Solo is a standalone, non-client/server way to execute Chef recipes on nodes.</td>
      </tr>

      <tr>
        <td>System Integration</td>

        <td>The act of making disparate systems in an infrastructure work together to provide application services and business value is
        system integration. It is where all the systems that have been configured are brought together to do their job.</td>
      </tr>

      <tr>
        <td>
          <a href="http://wiki.opscode.com/display/chef/Recipes#Recipes-Tags">Tags</a>
        </td>

        <td>Tags are an array attribute of nodes.</td>
      </tr>

      <tr>
        <td>Template</td>

        <td>Chef uses ERB templates to create dynamically generated configuration files. The template files themselves are stored in
        cookbooks and generated using the Erubis library as it is faster than the default implementation of ERB in the Ruby standard
        library.</td>
      </tr>

      <tr>
        <td>User</td>

        <td>In the Open Source Chef Server, users log into the Webui Management Console. In the Hosted Chef, users are credentialed
        entities used by humans to connect to Hosted Chef to manage the Organization.</td>
      </tr>

      <tr>
        <td>
          <a href="http://wiki.opscode.com/display/chef/Management+Console">Webui</a>
        </td>

        <td>Hosted Chef and the Open Source Chef Server have a web user interface Management Console that can be used to view and modify
        various parts of the environment.</td>
      </tr>
    </tbody>
  </table>
</div><br>

<div class="page-divider"></div>